{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OPT_hyperopt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmUldPYhoXIOVgT6Pi3hVq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffelfis/OrgaDatosTPs/blob/main/TP2/resources/OPT_hyperopt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSu_EYXuf8JJ"
      },
      "source": [
        "# Lectura de datos de Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLQLYXM4f8JK",
        "outputId": "cbb49aa9-ad51-4582-80b7-6ff272a035db"
      },
      "source": [
        "# Lectura de Dataset desde Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpNLc4kPyAbf"
      },
      "source": [
        "# Para importar funciones customizadas\n",
        "\n",
        "Hay que especificar la ruta de donde se encuentra el módulo (archivo `.py`) para buscar las funciones.\n",
        "\n",
        "La lectura puede ser muy celosa: las indentaciones son de 4 espacios no tabulaciones.\n",
        "\n",
        "https://colab.research.google.com/drive/1uvHuizCBqFgvbCwEhK7FvU8JW0AfxgJw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeM6NwOeyKur"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/75.06 - Organización de Datos/TP2/resources')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phUPpKV5ie5n"
      },
      "source": [
        "# Carga de librerías y directorios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhFuDtsTifvX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Métrica de evaluación\n",
        "from sklearn.metrics import f1_score\n",
        "# fold_score = f1_score(y_test, prediction, average='micro')\n",
        "# Se especifica average por tener un target multiclase\n",
        "\n",
        "# Clasificador\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Para la división en k-folds\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Para pasar parámetros varias veces a una función\n",
        "from functools import partial\n",
        "\n",
        "# Paquetes de hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "# Cuando se especifica un espacio de distribuciones de Integers a veces\n",
        "# devuelve Floats. scope resuelve este problema\n",
        "from hyperopt.pyll.base import scope\n",
        "\n",
        "# Librería para guardar los Trials.\n",
        "import pickle\n",
        "\n",
        "# Función para cambiar tipos de datos\n",
        "from utilidades import cambio_tipos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sINS71mixTT"
      },
      "source": [
        "# Rutas de los archivos a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCBPCSsUisx2"
      },
      "source": [
        "# Ruta train_values.csv\n",
        "dir_values = '/content/drive/My Drive/75.06 - Organización de Datos/TP1/Data/train_values.csv'\n",
        "# Ruta train_labels.csv\n",
        "dir_labels = '/content/drive/My Drive/75.06 - Organización de Datos/TP1/Data/train_labels.csv'\n",
        "# Ruta de Binary Encodings para train_values.csv\n",
        "dir_resources = '/content/drive/My Drive/75.06 - Organización de Datos/TP2/resources'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U10d9Z3cjmEn"
      },
      "source": [
        "---\n",
        "#Entrenamiento\n",
        "---\n",
        "### Carga de train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GU7d7LENLcs"
      },
      "source": [
        "columnas = ['building_id',\n",
        " 'geo_level_1_id',\n",
        " 'geo_level_2_id',\n",
        " 'geo_level_3_id',\n",
        " 'count_floors_pre_eq',\n",
        " 'age',\n",
        " 'area_percentage',\n",
        " 'height_percentage',\n",
        " 'has_superstructure_adobe_mud',\n",
        " 'has_superstructure_mud_mortar_stone',\n",
        " 'has_superstructure_stone_flag',\n",
        " 'has_superstructure_cement_mortar_stone',\n",
        " 'has_superstructure_mud_mortar_brick',\n",
        " 'has_superstructure_cement_mortar_brick',\n",
        " 'has_superstructure_timber',\n",
        " 'has_superstructure_bamboo',\n",
        " 'has_superstructure_rc_non_engineered',\n",
        " 'has_superstructure_rc_engineered',\n",
        " 'has_superstructure_other',\n",
        " 'count_families',\n",
        " 'has_secondary_use',\n",
        " 'has_secondary_use_agriculture',\n",
        " 'has_secondary_use_hotel',\n",
        " 'has_secondary_use_rental',\n",
        " 'has_secondary_use_institution',\n",
        " 'has_secondary_use_school',\n",
        " 'has_secondary_use_industry',\n",
        " 'has_secondary_use_health_post',\n",
        " 'has_secondary_use_gov_office',\n",
        " 'has_secondary_use_use_police',\n",
        " 'has_secondary_use_other']\n",
        " \n",
        "# Carga de train_values.csv\n",
        "train = pd.read_csv(dir_values, usecols=columnas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gllv83PimADJ"
      },
      "source": [
        "### Cambio de tipos de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrZAEMGAj-tJ"
      },
      "source": [
        "train = cambio_tipos(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEOYhxbpbfaN"
      },
      "source": [
        "### Carga de columnas codificadas: Binary Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i_00Z0Cbmyb"
      },
      "source": [
        "# 28 columnas más.\n",
        "train = train.join(pd.read_csv(dir_resources+f'/BE_train.csv', dtype='uint8'))\n",
        "\n",
        "X = train.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBiOdGmvWsIP"
      },
      "source": [
        "### Carga de labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4DACqZZWrLe"
      },
      "source": [
        "# Carga de train_labels.csv\n",
        "labels = pd.read_csv(dir_labels, usecols=['damage_grade'], dtype='uint8')\n",
        "\n",
        "y = labels.damage_grade.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcZ19DiAtEey"
      },
      "source": [
        "# Hyperopt\n",
        "Usa Tree-Structured Parzen Estimator (TPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJxVnjjftoBo"
      },
      "source": [
        "- Aquí la función de optimización recibe directamente un diccionario.\n",
        "- Aquí se define la cantidad de __splits para Cross Validation__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTQjICeYtuZn"
      },
      "source": [
        "# params: lista de valores de parámetros (value)\n",
        "# x: features\n",
        "# y: target\n",
        "\n",
        "def optimize(params, x, y):\n",
        "  # Se instancia el modelo con el diccionario de parámetros\n",
        "  model = RandomForestClassifier(**params)\n",
        "  # Hay que realizar el k-folding\n",
        "  kf = StratifiedKFold(n_splits=5)\n",
        "  # Lista de scores\n",
        "  scores = []\n",
        "  # Se dividen los datos\n",
        "  for index in kf.split(X=x, y=y):\n",
        "    train_index, test_index = index[0], index[1]\n",
        "    X_train = x[train_index]\n",
        "    y_train = y[train_index]\n",
        "    X_test = x[test_index]\n",
        "    y_test = y[test_index]\n",
        "    # Entrenamiento del k-fold\n",
        "    model.fit(X_train, y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "    # average='micro' es necesario por ser un target multiclase\n",
        "    fold_score = f1_score(y_test, prediction, average='micro')\n",
        "    # Se agrega el score a la lista\n",
        "    scores.append(fold_score)\n",
        "  # Ahora hay que devolver la función para minimizar\n",
        "  return -1.0 * np.mean(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PPSD91huCdj"
      },
      "source": [
        "Para definir el espacio de parámetros hay que usar un diccionario y usar espacios dedicados de `hyperopt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcV5boqxu1Sr"
      },
      "source": [
        "# Los valores que requieren enteros tienen un scope de enteros\n",
        "param_space = {\n",
        "  'max_depth' : scope.int(hp.quniform('max_depth', 40, 60, 1)),\n",
        "  'n_estimators' : scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
        "  'criterion' : hp.choice('criterion', ['gini', 'entropy']),\n",
        "  'max_features' : hp.uniform('max_features', 0.05, 1)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie1bK9NuyiPr"
      },
      "source": [
        "Función para optimizar, sin `param_names`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPyeY3PJyaYv"
      },
      "source": [
        "optimization_function = partial(optimize, x=X, y=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFbZ5vHlyvZR"
      },
      "source": [
        "Se inicializan los trials. Para continuar con la optimización conviene tener por separado la celda que busca minimizar la función objetivo. Así los Trials acarrean las combinaciones usadas anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw_mdcmVyv2k"
      },
      "source": [
        "trials = Trials()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9Q3ZCTwzBHI"
      },
      "source": [
        "Aquí se usa la función `fmin` para minimizar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuDxnNIEzBk3",
        "outputId": "4644ea7f-213b-4b22-ac19-a93182dc5be1"
      },
      "source": [
        "result = fmin(fn=optimization_function, space=param_space, algo=tpe.suggest, max_evals=5, trials=trials)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [21:42<00:00, 260.56s/it, best loss: -0.729083917915015]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf9I04smznHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def1d09f-a72f-4d1b-f545-67d6576c039c"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 1, 'max_depth': 48.0, 'max_features': 0.8310276775795518, 'n_estimators': 47.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZU2fPL8uQu4"
      },
      "source": [
        "`criterion` indica la pocisión en el vector del parámetro indicado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXlP34fXmwz6"
      },
      "source": [
        "### Almacenamiento de Trials\n",
        "Para continuar la optimización.\n",
        "\n",
        "_Observación_: Recordar que luego hay que aumentar el número de `max_evals`, en `fmin`, para seguir acumulando pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_okFqy0myDS"
      },
      "source": [
        "# String con dirección de almacenamiento y nombre del archivo .pkl.\n",
        "trials_file_name = 'pickle/Trials_LGBMClassifier05.pkl'\n",
        "\n",
        "# Se crea una variable pickle y se abre en modo de escritura.\n",
        "# [También se crea el archivo en el directorio especificado por lgbm_file_name]\n",
        "trials_pickle = open(trials_file_name, 'wb')\n",
        "\n",
        "# Se usa el método dump con el modelo y el archivo creado en modo de esritura\n",
        "# para crear el pickle.\n",
        "pickle.dump(trials, trials_pickle)\n",
        "\n",
        "# Finalmente hay que cerrar la instancia del pickle.\n",
        "trials_pickle.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHVWe1gFm8j_"
      },
      "source": [
        "### Lectura de Trials\n",
        "\n",
        "_Observación_: Recordar que luego hay que aumentar el número de `max_evals`, en `fmin`, para seguir acumulando pruebas.\n",
        "\n",
        "Si se hicieron 60 pruebas entre los Trials anteriores y se quieren hacer 20 más entonces hay que usar `max_evals=80`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynuG8vHEm_Lg"
      },
      "source": [
        "# String con dirección de almacenamiento y nombre del archivo .pkl.\n",
        "file_name = 'pickle/Trials_LGBMClassifier05.pkl'\n",
        "\n",
        "# Se crea una variable para el archivo pickle y se abre con la dirección del\n",
        "# archivo en modo lectura. \n",
        "trials_pkl = open(file_name, 'rb')\n",
        "\n",
        "# Se carga el modelo pasando la variable creada, en la misma se encuentra\n",
        "# la dirección del archivo pickle.\n",
        "trials = pickle.load(trials_pkl)\n",
        "print('Modelo cargado')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}